{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryajani/algo-trading/blob/main/algotrade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLHcWzYsNhaR",
        "outputId": "739c20d6-9294-43fe-c9a1-ed681d6d9c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-f2c84696e758>:114: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
            "  cleaned_data['Year_Month'] = cleaned_data['Date'].dt.to_period('M')\n",
            "<ipython-input-11-f2c84696e758>:247: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  recovery_date_idx = cleaned_data[max_drawdown_end:][cleaned_data['curval'] >= previous_peak].index.min()\n",
            "<ipython-input-11-f2c84696e758>:287: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  sheet.update('A1', [cleaned_data.columns.tolist()] + data)  # A1 will be the header\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gspread\n",
        "\n",
        "\n",
        "\n",
        "# Define the ticker symbol for Nifty 50\n",
        "nifty_ticker = \"^NSEI\"\n",
        "\n",
        "# Fetch data for Nifty 50\n",
        "nifty_data = yf.Ticker(nifty_ticker)\n",
        "\n",
        "# Get historical market data (CHANGE TO 10 YEARS)\n",
        "historical_data = nifty_data.history(start=\"2014-01-01\", end=\"2024-12-31\")  # Fetch data for the past month\n",
        "\n",
        "# Drop unwanted columns: 'Volume', 'Dividends', 'Stock Splits'\n",
        "cleaned_data = historical_data.drop(columns=[\"Volume\", \"Dividends\", \"Stock Splits\"])\n",
        "\n",
        "cleaned_data.index = cleaned_data.index.astype(str)\n",
        "cleaned_data = cleaned_data.reset_index()\n",
        "\n",
        "# margin\n",
        "margin = 100000\n",
        "\n",
        "# 20SMA\n",
        "cleaned_data[\"20SMA\"] = cleaned_data[\"Close\"].rolling(window=20).mean()\n",
        "\n",
        "#100SMA\n",
        "cleaned_data[\"100SMA\"] = cleaned_data[\"Close\"].rolling(window=100).mean()\n",
        "\n",
        "# Create a Signal column to detect crossovers\n",
        "def detect_signal(data):\n",
        "    signals = []\n",
        "    for i in range(len(data)):\n",
        "        if i == 0:  # First row, no crossover to check\n",
        "            signals.append(\"Hold\")\n",
        "        else:\n",
        "            # Check for crossovers\n",
        "            prev_20sma = data[\"20SMA\"].iloc[i - 1]\n",
        "            prev_100sma = data[\"100SMA\"].iloc[i - 1]\n",
        "            curr_20sma = data[\"20SMA\"].iloc[i]\n",
        "            curr_100sma = data[\"100SMA\"].iloc[i]\n",
        "\n",
        "            if prev_20sma <= prev_100sma and curr_20sma > curr_100sma:\n",
        "                signals.append(\"Long\")  # Bullish crossover\n",
        "            elif prev_20sma >= prev_100sma and curr_20sma < curr_100sma:\n",
        "                signals.append(\"Short\")  # Bearish crossover\n",
        "            else:\n",
        "                signals.append(\"Hold\")  # No crossover\n",
        "    return signals\n",
        "\n",
        "\n",
        "# Apply the function to detect signals\n",
        "cleaned_data[\"Signal\"] = detect_signal(cleaned_data)\n",
        "\n",
        "# Profit\n",
        "# Initialize a variable to track the entry price\n",
        "entry_price = None\n",
        "\n",
        "# Create a new column 'Profit Percentage' to store the profit percentage after each valid Sell\n",
        "profP = []\n",
        "profV = []\n",
        "\n",
        "# Loop through the data to calculate profit percentages after each Sell signal\n",
        "for i in range(len(cleaned_data)):\n",
        "\n",
        "    curr_pos = cleaned_data[\"Signal\"].iloc[i]\n",
        "    exit_price = cleaned_data[\"Close\"].iloc[i]\n",
        "    if curr_pos == \"Long\" or curr_pos == \"Short\":\n",
        "        prev_pos = curr_pos\n",
        "        if not entry_price:\n",
        "            entry_price = exit_price\n",
        "            profP.append(None)\n",
        "            profV.append(None)\n",
        "        else:\n",
        "            q = margin/entry_price\n",
        "            curr_profP = (entry_price-exit_price)*100/entry_price\n",
        "            if curr_pos == \"Short\": # exit short\n",
        "                curr_profP *= -1\n",
        "            entry_price = exit_price\n",
        "            profP.append(curr_profP)\n",
        "            profV.append(curr_profP*margin/100)\n",
        "    elif i == len(cleaned_data)-1:\n",
        "        curr_profP = (entry_price-exit_price)*100/entry_price\n",
        "        if prev_pos == \"Short\":\n",
        "            curr_profP *= -1\n",
        "        profP.append(curr_profP)\n",
        "        profV.append(curr_profP*margin/100)\n",
        "    else:\n",
        "        profP.append(None)\n",
        "        profV.append(None)\n",
        "\n",
        "cleaned_data['Profit Percentage'] = profP\n",
        "cleaned_data['Profit Value'] = profV\n",
        "iter = []\n",
        "iterV = []\n",
        "\n",
        "\n",
        "# Ensure 'Date' column is in datetime format\n",
        "cleaned_data['Date'] = pd.to_datetime(cleaned_data['Date'])\n",
        "\n",
        "# Find the minimum and maximum dates\n",
        "min_date = cleaned_data['Date'].min()\n",
        "max_date = cleaned_data['Date'].max()\n",
        "\n",
        "# Calculate the total number of days between the min and max date\n",
        "number_days = (max_date - min_date).days\n",
        "\n",
        "# Extract year and month (year-month format)\n",
        "cleaned_data['Year_Month'] = cleaned_data['Date'].dt.to_period('M')\n",
        "\n",
        "# Find the number of unique year-month combinations\n",
        "number_months = cleaned_data['Year_Month'].nunique()\n",
        "\n",
        "cleaned_data = cleaned_data.drop(columns=['Year_Month'])\n",
        "cleaned_data['Date'] = cleaned_data['Date'].astype(str)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\" METRICS \"\"\"\n",
        "\n",
        "# total profit percentage\n",
        "profit_sum_p = cleaned_data['Profit Percentage'].sum()\n",
        "iter.append('Profit Percentage')\n",
        "iterV.append(profit_sum_p)\n",
        "\n",
        "# total profit value\n",
        "profit_sum_v = cleaned_data['Profit Value'].sum()\n",
        "iter.append('Profit Value')\n",
        "iterV.append(profit_sum_v)\n",
        "\n",
        "# max profit percentage\n",
        "profit_max_p = cleaned_data['Profit Percentage'].max()\n",
        "iter.append('Max Profit Percentage')\n",
        "iterV.append(profit_max_p)\n",
        "\n",
        "# max loss percentage\n",
        "profit_min_p = cleaned_data['Profit Percentage'].min()\n",
        "iter.append('Min Profit Percentage')\n",
        "iterV.append(profit_min_p)\n",
        "\n",
        "# number of win days\n",
        "num_win_days = (cleaned_data['Profit Percentage'] > 0).sum()\n",
        "iter.append('Number of Win Days')\n",
        "iterV.append(num_win_days)\n",
        "\n",
        "# number of loss days\n",
        "num_loss_days = (cleaned_data['Profit Percentage'] <= 0).sum()\n",
        "iter.append('Number of Loss Days')\n",
        "iterV.append(num_loss_days)\n",
        "\n",
        "# average monthly profit value\n",
        "avg_month_profit = profit_sum_v/number_months\n",
        "iter.append('Average monthly profit value')\n",
        "iterV.append(avg_month_profit)\n",
        "\n",
        "# average monthly profit percent\n",
        "avg_month_profit = profit_sum_p/number_months\n",
        "iter.append('Average monthly profit percent')\n",
        "iterV.append(avg_month_profit)\n",
        "\n",
        "# average profit on win days\n",
        "sum_win_profit_v = cleaned_data[cleaned_data['Profit Value'] >= 0]['Profit Value'].sum()\n",
        "avg_win_profit_v = sum_win_profit_v/num_win_days\n",
        "iter.append('Average win day profit value')\n",
        "iterV.append(avg_win_profit_v)\n",
        "\n",
        "# average profit on loss days\n",
        "sum_win_profit_v = cleaned_data[cleaned_data['Profit Value'] < 0]['Profit Value'].sum()\n",
        "avg_win_profit_v = sum_win_profit_v/num_win_days\n",
        "iter.append('Average loss day profit value')\n",
        "iterV.append(avg_win_profit_v)\n",
        "\n",
        "# win days percent\n",
        "win_days_percent = num_win_days/number_days*100\n",
        "iter.append('Win day %')\n",
        "iterV.append(win_days_percent)\n",
        "\n",
        "# loss days percent\n",
        "loss_days_percent = num_loss_days/number_days*100\n",
        "iter.append('loss day %')\n",
        "iterV.append(loss_days_percent)\n",
        "\n",
        "# max win streak\n",
        "max_win_streak = 0\n",
        "current_streak = 0\n",
        "\n",
        "# Loop through the values in the column\n",
        "for value in cleaned_data['Profit Percentage']:\n",
        "    if pd.notna(value) and value >= 0:\n",
        "        current_streak += 1  # Increase streak for positive values\n",
        "        max_win_streak = max(max_win_streak, current_streak)  # Update max streak if needed\n",
        "    elif value < 0:\n",
        "        current_streak = 0  # Reset streak for negative values\n",
        "    # No action for NaN (empty) values, they won't break the streak\n",
        "iter.append('Max W Streak')\n",
        "iterV.append(max_win_streak)\n",
        "\n",
        "# max loss streak\n",
        "max_loss_streak = 0\n",
        "current_streak = 0\n",
        "\n",
        "# Loop through the values in the column\n",
        "for value in cleaned_data['Profit Percentage']:\n",
        "    if pd.notna(value) and value < 0:\n",
        "        current_streak += 1  # Increase streak for positive values\n",
        "        max_loss_streak = max(max_loss_streak, current_streak)  # Update max streak if needed\n",
        "    elif value >= 0:\n",
        "        current_streak = 0  # Reset streak for negative values\n",
        "    # No action for NaN (empty) values, they won't break the streak\n",
        "iter.append('Max L Streak')\n",
        "iterV.append(max_loss_streak)\n",
        "\n",
        "# max draw down\n",
        "cleaned_data['curval'] = cleaned_data['Profit Value'] + margin\n",
        "cleaned_data['curmax'] = cleaned_data['curval'].cummax()\n",
        "cleaned_data['drawdown'] = (cleaned_data['curval'] - cleaned_data['curmax'])/cleaned_data['curmax']\n",
        "max_drawdown = cleaned_data['drawdown'].min()*-100\n",
        "iter.append('max drawdown')\n",
        "iterV.append(max_drawdown)\n",
        "\n",
        "# max draw down end date\n",
        "max_drawdown_end = cleaned_data['drawdown'].idxmin()\n",
        "end_date = cleaned_data.loc[max_drawdown_end, 'Date']\n",
        "iter.append('MDD End Date')\n",
        "iterV.append(end_date)\n",
        "\n",
        "# max draw down start date\n",
        "max_drawdown_start = cleaned_data.loc[:max_drawdown_end, 'curval'].idxmax()\n",
        "start_date = cleaned_data.loc[max_drawdown_start, 'Date']\n",
        "iter.append('MDD Start Date')\n",
        "iterV.append(start_date)\n",
        "\n",
        "# number of drawdown days\n",
        "start_date = pd.to_datetime(start_date)\n",
        "end_date = pd.to_datetime(end_date)\n",
        "drawdown_days = (end_date - start_date).days\n",
        "iter.append('Number of drawdown days')\n",
        "iterV.append(drawdown_days)\n",
        "\n",
        "# MDD recovery\n",
        "previous_peak = cleaned_data.loc[max_drawdown_start, 'curval']\n",
        "recovery_date_idx = cleaned_data[max_drawdown_end:][cleaned_data['curval'] >= previous_peak].index.min()\n",
        "if pd.notna(recovery_date_idx):\n",
        "    recovery_date = cleaned_data.loc[recovery_date_idx, 'date']\n",
        "    end_date = cleaned_data.loc[max_drawdown_end, 'date']\n",
        "    recovery_days = (recovery_date - end_date).days\n",
        "else:\n",
        "    recovery_days = \"NA\"\n",
        "iter.append('MDD Recovery Days')\n",
        "iterV.append(recovery_days)\n",
        "\n",
        "\n",
        "\"\"\" FOR UPDATING GOOGLE SHEETS \"\"\"\n",
        "# Authenticate user\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Get default credentials using google-auth\n",
        "creds, project = default()\n",
        "\n",
        "# Authorize gspread with the credentials\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "# Open the Google Sheet (replace \"Your Google Sheet Name\" with the actual sheet name)\n",
        "sheet = client.open_by_url(\"https://docs.google.com/spreadsheets/d/1m6kylRZBnOiUDqZe0-_viGpHWpDw08aHeT7mmAUw_Tg/edit?gid=1902718297#gid=1902718297\").sheet1\n",
        "\n",
        "# Handle NaN and infinity values by replacing them with None\n",
        "\n",
        "data = cleaned_data.replace([float('inf'), float('-inf')], None)  # Replace infinities with None\n",
        "data = data.fillna(\"\")  # Replace NaNs with None\n",
        "# data.index = data.index.astype(str)\n",
        "# data = data.reset_index()\n",
        "\n",
        "\n",
        "\n",
        "# Convert the DataFrame to a list of lists\n",
        "data = data.values.tolist()\n",
        "\n",
        "# Clear the existing data in the sheet\n",
        "sheet.clear()\n",
        "\n",
        "# Update the sheet with new data, including column headers\n",
        "sheet.update('A1', [cleaned_data.columns.tolist()] + data)  # A1 will be the header\n",
        "\n",
        "# Get all values of the specific column from Google Sheets\n",
        "col_index = cleaned_data.columns.get_loc(\"Profit Percentage\") + 1  # Adjust for 1-based index in Google Sheets\n",
        "col_values = sheet.col_values(col_index)\n",
        "\n",
        "# Find the next available row in the column\n",
        "next_row = len(col_values) + 2\n",
        "\n",
        "# Update the cell below the last row with the sum\n",
        "\n",
        "for i in range(len(iter)):\n",
        "    sheet.update_cell(next_row+i, col_index, iter[i])\n",
        "    sheet.update_cell(next_row+i, col_index+1, str(iterV[i]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vKyy_wn1vvNx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}